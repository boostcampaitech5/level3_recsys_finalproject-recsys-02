Sat 08 Jul 2023 13:40:01 INFO  ['/opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py', '--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme="hmac-sha256"', '--Session.key=b"592d033b-cc73-45c1-bde7-7c138d62a9e8"', '--shell=9002', '--transport="tcp"', '--iopub=9004', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6318OfaCSifKkcge.json']
Sat 08 Jul 2023 13:40:01 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = /opt/ml/wine/dataset/train_data
checkpoint_dir = saved
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 500
train_batch_size = 1024
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [8, 1, 1]}, 'order': 'RO', 'group_by': 'user', 'mode': 'labeled'}
repeatable = False
metrics = ['AUC', 'LogLoss']
topk = [10]
valid_metric = AUC
valid_metric_bigger = True
eval_batch_size = 1024
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = {'user_rating': 3.5}
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'user_rating', 'item_id'], 'user': ['user_id', 'count', 'mean'], 'item': ['item_id', 'country', 'region', 'winery', 'winetype', 'grape', 'vintage', 'price', 'rating', 'num_votes', 'wine_style', 'Red Fruit_count', 'Tropical_count', 'Tree Fruit_count', 'Oaky_count', 'Ageing_count', 'Black Fruit_count', 'Citrus_count', 'Dried Fruit_count', 'Earthy_count', 'Floral_count', 'Microbio_count', 'Spices_count', 'Vegetal_count']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 10
mlp_hidden_size = [256, 256, 256]
cross_layer_num = 6
reg_weight = 2
dropout_prob = 0.2
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.CONTEXT
device = cuda
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.VALUE
single_spec = True
local_rank = 0
eval_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}


Sat 08 Jul 2023 13:40:57 INFO  train_data
The number of users: 1154808
Average actions of users: 5.042714496881297
The number of items: 74923
Average actions of items: 306.8318668001475
The number of inters: 5823362
The sparsity of the dataset: 99.99326947648896%
Remain Fields: ['user_id', 'item_id', 'count', 'mean', 'country', 'region', 'winery', 'winetype', 'grape', 'vintage', 'price', 'rating', 'num_votes', 'wine_style', 'Red Fruit_count', 'Tropical_count', 'Tree Fruit_count', 'Oaky_count', 'Ageing_count', 'Black Fruit_count', 'Citrus_count', 'Dried Fruit_count', 'Earthy_count', 'Floral_count', 'Microbio_count', 'Spices_count', 'Vegetal_count', 'label']
Sat 08 Jul 2023 13:41:30 INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Sat 08 Jul 2023 13:41:30 INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [8, 1, 1]}, 'order': 'RO', 'group_by': 'user', 'mode': 'labeled'}]
Sat 08 Jul 2023 13:41:34 INFO  DCN(
  (token_embedding_table): FMEmbedding(
    (embedding): Embedding(1244172, 10)
  )
  (token_seq_embedding_table): ModuleList(
    (0): Embedding(805, 10)
  )
  (first_order_linear): FMFirstOrderLinear(
    (token_embedding_table): FMEmbedding(
      (embedding): Embedding(1244172, 1)
    )
    (token_seq_embedding_table): ModuleList(
      (0): Embedding(805, 1)
    )
  )
  (cross_layer_w): ParameterList(
      (0): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (2): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (3): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (4): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (5): Parameter containing: [torch.float32 of size 90 (GPU 0)]
  )
  (cross_layer_b): ParameterList(
      (0): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (2): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (3): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (4): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (5): Parameter containing: [torch.float32 of size 90 (GPU 0)]
  )
  (mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=90, out_features=256, bias=True)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Dropout(p=0.2, inplace=False)
      (5): Linear(in_features=256, out_features=256, bias=True)
      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): ReLU()
      (8): Dropout(p=0.2, inplace=False)
      (9): Linear(in_features=256, out_features=256, bias=True)
      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU()
    )
  )
  (predict_layer): Linear(in_features=346, out_features=1, bias=True)
  (reg_loss): RegLoss()
  (sigmoid): Sigmoid()
  (loss): BCEWithLogitsLoss()
)
Trainable parameters: 13852591
Sat 08 Jul 2023 13:41:37 INFO  FLOPs: 157760.0
Sat 08 Jul 2023 13:42:32 INFO  epoch 0 training [time: 55.33s, train loss: 94436.2676]
Sat 08 Jul 2023 13:42:34 INFO  epoch 0 evaluating [time: 2.50s, valid_score: 0.825600]
Sat 08 Jul 2023 13:42:34 INFO  valid result: 
auc : 0.8256    logloss : 0.2291
Sat 08 Jul 2023 13:42:35 INFO  Saving current: saved/DCN-Jul-08-2023_13-41-37.pth
Sat 08 Jul 2023 13:43:29 INFO  epoch 1 training [time: 54.53s, train loss: 824.6972]
Sat 08 Jul 2023 13:43:32 INFO  epoch 1 evaluating [time: 2.40s, valid_score: 0.819600]
Sat 08 Jul 2023 13:43:32 INFO  valid result: 
auc : 0.8196    logloss : 0.2468
Sat 08 Jul 2023 13:44:25 INFO  epoch 2 training [time: 53.67s, train loss: 759.2942]
Sat 08 Jul 2023 13:44:28 INFO  epoch 2 evaluating [time: 2.46s, valid_score: 0.818000]
Sat 08 Jul 2023 13:44:28 INFO  valid result: 
auc : 0.818    logloss : 0.2617
Sat 08 Jul 2023 13:45:21 INFO  epoch 3 training [time: 53.51s, train loss: 718.4254]
Sat 08 Jul 2023 13:45:24 INFO  epoch 3 evaluating [time: 2.35s, valid_score: 0.817400]
Sat 08 Jul 2023 13:45:24 INFO  valid result: 
auc : 0.8174    logloss : 0.2711
Sat 08 Jul 2023 13:46:19 INFO  epoch 4 training [time: 54.88s, train loss: 687.9172]
Sat 08 Jul 2023 13:46:22 INFO  epoch 4 evaluating [time: 3.01s, valid_score: 0.822500]
Sat 08 Jul 2023 13:46:22 INFO  valid result: 
auc : 0.8225    logloss : 0.2763
Sat 08 Jul 2023 13:47:18 INFO  epoch 5 training [time: 56.22s, train loss: 666.4800]
Sat 08 Jul 2023 13:47:20 INFO  epoch 5 evaluating [time: 2.41s, valid_score: 0.818200]
Sat 08 Jul 2023 13:47:20 INFO  valid result: 
auc : 0.8182    logloss : 0.283
Sat 08 Jul 2023 13:48:09 INFO  epoch 6 training [time: 49.18s, train loss: 647.6986]
Sat 08 Jul 2023 13:48:12 INFO  epoch 6 evaluating [time: 2.44s, valid_score: 0.823600]
Sat 08 Jul 2023 13:48:12 INFO  valid result: 
auc : 0.8236    logloss : 0.2776
Sat 08 Jul 2023 13:49:04 INFO  epoch 7 training [time: 52.38s, train loss: 631.5963]
Sat 08 Jul 2023 13:49:07 INFO  epoch 7 evaluating [time: 2.40s, valid_score: 0.811700]
Sat 08 Jul 2023 13:49:07 INFO  valid result: 
auc : 0.8117    logloss : 0.2958
Sat 08 Jul 2023 13:50:00 INFO  epoch 8 training [time: 53.73s, train loss: 616.0003]
Sat 08 Jul 2023 13:50:03 INFO  epoch 8 evaluating [time: 2.35s, valid_score: 0.815400]
Sat 08 Jul 2023 13:50:03 INFO  valid result: 
auc : 0.8154    logloss : 0.3005
Sat 08 Jul 2023 13:50:58 INFO  epoch 9 training [time: 54.89s, train loss: 602.5356]
Sat 08 Jul 2023 13:51:00 INFO  epoch 9 evaluating [time: 2.33s, valid_score: 0.817800]
Sat 08 Jul 2023 13:51:00 INFO  valid result: 
auc : 0.8178    logloss : 0.3034
Sat 08 Jul 2023 13:51:53 INFO  epoch 10 training [time: 53.47s, train loss: 590.1266]
Sat 08 Jul 2023 13:51:56 INFO  epoch 10 evaluating [time: 2.36s, valid_score: 0.815400]
Sat 08 Jul 2023 13:51:56 INFO  valid result: 
auc : 0.8154    logloss : 0.2991
Sat 08 Jul 2023 13:52:53 INFO  epoch 11 training [time: 56.84s, train loss: 578.7616]
Sat 08 Jul 2023 13:53:00 INFO  epoch 11 evaluating [time: 7.15s, valid_score: 0.810800]
Sat 08 Jul 2023 13:53:00 INFO  valid result: 
auc : 0.8108    logloss : 0.3027
Sat 08 Jul 2023 13:53:00 INFO  Finished training, best eval result in epoch 0
Sat 08 Jul 2023 13:53:00 INFO  Loading model structure and parameters from saved/DCN-Jul-08-2023_13-41-37.pth
Sat 08 Jul 2023 13:53:10 INFO  best valid : OrderedDict([('auc', 0.8256), ('logloss', 0.2291)])
Sat 08 Jul 2023 13:53:10 INFO  test result: OrderedDict([('auc', 0.8161), ('logloss', 0.2433)])
Sat 08 Jul 2023 13:56:23 INFO  ['/opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py', '--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme="hmac-sha256"', '--Session.key=b"592d033b-cc73-45c1-bde7-7c138d62a9e8"', '--shell=9002', '--transport="tcp"', '--iopub=9004', '--f=/root/.local/share/jupyter/runtime/kernel-v2-6318OfaCSifKkcge.json']
Sat 08 Jul 2023 13:56:23 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = /opt/ml/wine/dataset/train_data
checkpoint_dir = saved
show_progress = False
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 500
train_batch_size = 1024
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [8, 1, 1]}, 'order': 'RO', 'group_by': None, 'mode': 'labeled'}
repeatable = False
metrics = ['AUC', 'LogLoss']
topk = [10]
valid_metric = AUC
valid_metric_bigger = True
eval_batch_size = 1024
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = user_rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = {'user_rating': 4}
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'user_rating', 'item_id'], 'user': ['user_id', 'count', 'mean'], 'item': ['item_id', 'country', 'region', 'winery', 'winetype', 'grape', 'vintage', 'price', 'rating', 'num_votes', 'wine_style', 'Red Fruit_count', 'Tropical_count', 'Tree Fruit_count', 'Oaky_count', 'Ageing_count', 'Black Fruit_count', 'Citrus_count', 'Dried Fruit_count', 'Earthy_count', 'Floral_count', 'Microbio_count', 'Spices_count', 'Vegetal_count']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = [0,inf)
item_inter_num_interval = [0,inf)
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 10
mlp_hidden_size = [256, 256, 256]
cross_layer_num = 6
reg_weight = 2
dropout_prob = 0.2
numerical_features = []
discretization = None
kg_reverse_r = False
entity_kg_num_interval = [0,inf)
relation_kg_num_interval = [0,inf)
MODEL_TYPE = ModelType.CONTEXT
device = cuda
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.VALUE
single_spec = True
local_rank = 0
eval_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}


Sat 08 Jul 2023 13:57:25 INFO  train_data
The number of users: 1154808
Average actions of users: 5.042714496881297
The number of items: 74923
Average actions of items: 306.8318668001475
The number of inters: 5823362
The sparsity of the dataset: 99.99326947648896%
Remain Fields: ['user_id', 'item_id', 'count', 'mean', 'country', 'region', 'winery', 'winetype', 'grape', 'vintage', 'price', 'rating', 'num_votes', 'wine_style', 'Red Fruit_count', 'Tropical_count', 'Tree Fruit_count', 'Oaky_count', 'Ageing_count', 'Black Fruit_count', 'Citrus_count', 'Dried Fruit_count', 'Earthy_count', 'Floral_count', 'Microbio_count', 'Spices_count', 'Vegetal_count', 'label']
Sat 08 Jul 2023 13:57:35 INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Sat 08 Jul 2023 13:57:35 INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [8, 1, 1]}, 'order': 'RO', 'group_by': None, 'mode': 'labeled'}]
Sat 08 Jul 2023 13:57:35 INFO  DCN(
  (token_embedding_table): FMEmbedding(
    (embedding): Embedding(1244172, 10)
  )
  (token_seq_embedding_table): ModuleList(
    (0): Embedding(805, 10)
  )
  (first_order_linear): FMFirstOrderLinear(
    (token_embedding_table): FMEmbedding(
      (embedding): Embedding(1244172, 1)
    )
    (token_seq_embedding_table): ModuleList(
      (0): Embedding(805, 1)
    )
  )
  (cross_layer_w): ParameterList(
      (0): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (2): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (3): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (4): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (5): Parameter containing: [torch.float32 of size 90 (GPU 0)]
  )
  (cross_layer_b): ParameterList(
      (0): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (1): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (2): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (3): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (4): Parameter containing: [torch.float32 of size 90 (GPU 0)]
      (5): Parameter containing: [torch.float32 of size 90 (GPU 0)]
  )
  (mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=90, out_features=256, bias=True)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Dropout(p=0.2, inplace=False)
      (5): Linear(in_features=256, out_features=256, bias=True)
      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): ReLU()
      (8): Dropout(p=0.2, inplace=False)
      (9): Linear(in_features=256, out_features=256, bias=True)
      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): ReLU()
    )
  )
  (predict_layer): Linear(in_features=346, out_features=1, bias=True)
  (reg_loss): RegLoss()
  (sigmoid): Sigmoid()
  (loss): BCEWithLogitsLoss()
)
Trainable parameters: 13852591
Sat 08 Jul 2023 13:57:35 INFO  FLOPs: 157760.0
Sat 08 Jul 2023 13:59:17 INFO  epoch 0 training [time: 101.42s, train loss: 95292.1080]
Sat 08 Jul 2023 13:59:37 INFO  epoch 0 evaluating [time: 19.98s, valid_score: 0.822600]
Sat 08 Jul 2023 13:59:37 INFO  valid result: 
auc : 0.8226    logloss : 0.402
Sat 08 Jul 2023 13:59:37 INFO  Saving current: saved/DCN-Jul-08-2023_13-57-35.pth
Sat 08 Jul 2023 14:01:20 INFO  epoch 1 training [time: 103.15s, train loss: 1610.0832]
Sat 08 Jul 2023 14:01:40 INFO  epoch 1 evaluating [time: 19.92s, valid_score: 0.819200]
Sat 08 Jul 2023 14:01:40 INFO  valid result: 
auc : 0.8192    logloss : 0.411
Sat 08 Jul 2023 14:03:24 INFO  epoch 2 training [time: 104.35s, train loss: 1485.5288]
Sat 08 Jul 2023 14:03:44 INFO  epoch 2 evaluating [time: 19.95s, valid_score: 0.815300]
Sat 08 Jul 2023 14:03:44 INFO  valid result: 
auc : 0.8153    logloss : 0.422
Sat 08 Jul 2023 14:05:28 INFO  epoch 3 training [time: 103.75s, train loss: 1391.2325]
Sat 08 Jul 2023 14:05:49 INFO  epoch 3 evaluating [time: 20.66s, valid_score: 0.816600]
Sat 08 Jul 2023 14:05:49 INFO  valid result: 
auc : 0.8166    logloss : 0.4273
Sat 08 Jul 2023 14:07:33 INFO  epoch 4 training [time: 103.71s, train loss: 1338.3284]
Sat 08 Jul 2023 14:07:53 INFO  epoch 4 evaluating [time: 20.31s, valid_score: 0.814600]
Sat 08 Jul 2023 14:07:53 INFO  valid result: 
auc : 0.8146    logloss : 0.4372
Sat 08 Jul 2023 14:09:36 INFO  epoch 5 training [time: 102.67s, train loss: 1299.0728]
Sat 08 Jul 2023 14:09:55 INFO  epoch 5 evaluating [time: 19.52s, valid_score: 0.815100]
Sat 08 Jul 2023 14:09:55 INFO  valid result: 
auc : 0.8151    logloss : 0.4461
Sat 08 Jul 2023 14:11:38 INFO  epoch 6 training [time: 103.40s, train loss: 1265.3993]
Sat 08 Jul 2023 14:11:59 INFO  epoch 6 evaluating [time: 20.01s, valid_score: 0.814600]
Sat 08 Jul 2023 14:11:59 INFO  valid result: 
auc : 0.8146    logloss : 0.4436
Sat 08 Jul 2023 14:13:45 INFO  epoch 7 training [time: 106.44s, train loss: 1236.3531]
Sat 08 Jul 2023 14:14:05 INFO  epoch 7 evaluating [time: 19.70s, valid_score: 0.813200]
Sat 08 Jul 2023 14:14:05 INFO  valid result: 
auc : 0.8132    logloss : 0.4547
Sat 08 Jul 2023 14:15:29 INFO  epoch 8 training [time: 84.48s, train loss: 1210.6325]
Sat 08 Jul 2023 14:15:41 INFO  epoch 8 evaluating [time: 11.32s, valid_score: 0.806000]
Sat 08 Jul 2023 14:15:41 INFO  valid result: 
auc : 0.806    logloss : 0.4635
Sat 08 Jul 2023 14:16:42 INFO  epoch 9 training [time: 61.34s, train loss: 1187.6381]
Sat 08 Jul 2023 14:16:44 INFO  epoch 9 evaluating [time: 2.62s, valid_score: 0.811400]
Sat 08 Jul 2023 14:16:44 INFO  valid result: 
auc : 0.8114    logloss : 0.4628
Sat 08 Jul 2023 14:17:50 INFO  epoch 10 training [time: 65.06s, train loss: 1167.7888]
Sat 08 Jul 2023 14:18:09 INFO  epoch 10 evaluating [time: 19.56s, valid_score: 0.805000]
Sat 08 Jul 2023 14:18:09 INFO  valid result: 
auc : 0.805    logloss : 0.4714
Sat 08 Jul 2023 14:19:47 INFO  epoch 11 training [time: 98.16s, train loss: 1148.0450]
Sat 08 Jul 2023 14:20:08 INFO  epoch 11 evaluating [time: 20.48s, valid_score: 0.811100]
Sat 08 Jul 2023 14:20:08 INFO  valid result: 
auc : 0.8111    logloss : 0.4715
Sat 08 Jul 2023 14:20:08 INFO  Finished training, best eval result in epoch 0
Sat 08 Jul 2023 14:20:08 INFO  Loading model structure and parameters from saved/DCN-Jul-08-2023_13-57-35.pth
Sat 08 Jul 2023 14:20:28 INFO  best valid : OrderedDict([('auc', 0.8226), ('logloss', 0.402)])
Sat 08 Jul 2023 14:20:28 INFO  test result: OrderedDict([('auc', 0.8226), ('logloss', 0.4027)])
