{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "from typing import Union, Tuple, List\n",
    "from transformers import BertConfig, BertForPreTraining, BertTokenizerFast\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import Union, Tuple, List\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "# from IPython.display import Image\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer\n",
    "from transformers.utils import logging\n",
    "from transformers import BertConfig, BertForPreTraining, BertTokenizerFast\n",
    "from filelock import FileLock\n",
    "import time\n",
    "import pickle\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import argparse\n",
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer\n",
    "from datetime import datetime, date\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "# from IPython.display import Image\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import os\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.utils import logging\n",
    "logger = logging.get_logger(__name__)\n",
    "from filelock import FileLock\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('/opt/ml/wine/data/wine_df.csv')\n",
    "review_df = pd.read_csv('/opt/ml/wine/data/review_df_total.csv',encoding = 'utf-8-sig').loc[:,['user_url','rating','text','wine_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/wine/code/data/feature_map/item2idx.json','r') as f:\n",
    "    item2idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df[review_df['text'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['text'] = review_df['text'].apply(lambda x: x + '.' if x[-1] != '.' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_english_and_digits(text):\n",
    "    # Remove any characters that are not English alphabets, digits, periods, or commas at the end of sentences\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9\\s.,]', '', text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['text'] = review_df['text'].apply(keep_english_and_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['wine_id'] = review_df['wine_url'].map(item2idx)\n",
    "review_df = review_df[review_df['wine_id'].isna()==False]\n",
    "review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_df = wine_df.filter(like='_child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = {}\n",
    "import ast\n",
    "def str2dict(x):\n",
    "    try: return ast.literal_eval(x)\n",
    "    except: return {}\n",
    "def get_keys(x):\n",
    "    return set(x.keys())\n",
    "\n",
    "for col in note_df.columns:\n",
    "    note_df.loc[:,col] = note_df.loc[:,col].apply(str2dict)\n",
    "    sub_note = set()\n",
    "    for i in tqdm(range(len(note_df))):\n",
    "        subs = get_keys(note_df[col][i])\n",
    "        sub_note = sub_note | subs\n",
    "    notes[col.replace('_child','')] = sub_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_note = review_df.drop(['rating','wine_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 기본 정보 multi label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_basic_info = wine_df.loc[:, ['url','country','region','grape','winetype']]\n",
    "wine_basic_info['wine_id'] = wine_basic_info['url'].map(item2idx)\n",
    "wine_basic_info= wine_basic_info[wine_basic_info['wine_id'].isna()==False]\n",
    "wine_basic_info['wine_id'] = wine_basic_info['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_note_in_review(text, notes_data):\n",
    "    text = text.lower()\n",
    "    result = []\n",
    "    for key in notes:\n",
    "        if any(word in text for word in notes[key]):\n",
    "            result.append(1)\n",
    "        else: result.append(0)\n",
    "    return result\n",
    "\n",
    "def marking_data(df, notes_data):\n",
    "    df.reset_index(inplace = True)\n",
    "    data = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        note_onehot = check_note_in_review(df.loc[i,'text'], notes_data)\n",
    "        tmp = {}\n",
    "        tmp['text'] = df.loc[i,'text']\n",
    "        tmp['label'] = note_onehot\n",
    "        data.append(tmp)\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def parallel_dataframe_2input(func, df, notes_data, num_cpu):\n",
    "\n",
    "    for key in notes_data: notes_data[key] = set(notes_data[key])\n",
    "    chunks = np.array_split(df, num_cpu)\n",
    "\n",
    "    print('Parallelizing with ' +str(num_cpu)+'cores')\n",
    "    with Parallel(n_jobs = num_cpu, backend=\"multiprocessing\") as parallel:\n",
    "        results = parallel(delayed(func)(chunks[i], notes_data) for i in range(num_cpu))\n",
    "\n",
    "    for i,data in enumerate(results):\n",
    "        if i == 0:\n",
    "            output = data\n",
    "        else:\n",
    "            output = pd.concat([output, data], axis=0)\n",
    "    output.reset_index(inplace = True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.DataFrame(text_with_note.loc[:,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallelizing with 8cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928506/928506 [02:55<00:00, 5285.60it/s]\n",
      "100%|██████████| 928506/928506 [02:56<00:00, 5273.20it/s]\n",
      "100%|██████████| 928506/928506 [02:59<00:00, 5182.18it/s]\n",
      "100%|██████████| 928506/928506 [03:00<00:00, 5133.80it/s]\n",
      "100%|██████████| 928506/928506 [03:00<00:00, 5132.09it/s]\n",
      "100%|██████████| 928506/928506 [03:00<00:00, 5152.50it/s]\n",
      "100%|██████████| 928505/928505 [03:02<00:00, 5089.78it/s]\n",
      "100%|█████████▉| 925608/928506 [03:07<00:00, 7271.87it/s]\n",
      "100%|██████████| 928506/928506 [03:07<00:00, 4946.01it/s]"
     ]
    }
   ],
   "source": [
    "text_with_notelabel = parallel_dataframe_2input(marking_data, text, notes, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_notelabel.to_csv('/opt/ml/wine/data/text_with_notelabel.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            truncation = True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습 문장 최대 길이 :',max(len(l) for l in text_with_notelabel['text']))\n",
    "print('학습 문장의 평균 길이 :',sum(map(len, text_with_notelabel['text']))/len(text_with_notelabel['text']))\n",
    "\n",
    "plt.hist([len(s) for s in text_with_notelabel['text']], bins=50)\n",
    "plt.xlabel('length of data')\n",
    "plt.ylabel('number of data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "train_size = 0.8\n",
    "train_dataset = text_with_notelabel.sample(frac=train_size,random_state=200)\n",
    "test_dataset = text_with_notelabel.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"FULL Dataset: {}\".format(text_with_notelabel.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, 156)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 512\n",
    "VALID_BATCH_SIZE = 1024\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, num_labels)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "model = BERTClass(len(text_with_notelabel['label'][0]))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for data in tqdm(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info = pd.read_csv('/opt/ml/wine/data/basic_info_total.csv')\n",
    "wine_df = pd.read_csv('/opt/ml/wine/data/wine_df.csv')\n",
    "wine_info = wine_df.loc[:, ['url','winetype']].merge(basic_info, on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def str2list(x):\n",
    "    try: return ast.literal_eval(x)\n",
    "    except: return ['None']\n",
    "\n",
    "def get_all_grapes(wine_info):\n",
    "    \n",
    "    unique_grape = defaultdict(int)\n",
    "    for grapes in tqdm(wine_info['grapes']):\n",
    "        for grape in grapes:\n",
    "            grape = re.sub(r'\\d+%_', '', grape).lower()\n",
    "            unique_grape[grape] += 1\n",
    "\n",
    "    return dict(sorted(unique_grape.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grape_encoding(wine_info, grape2idx, threshold):\n",
    "    wine_info.reset_index(drop = True, inplace= True)\n",
    "    grape_onehot = []\n",
    "    for grapes in wine_info['grapes']:\n",
    "        tmp = [0 for _ in range(len(grape2idx))]\n",
    "        for grape in grapes:\n",
    "            if grape in grape2idx:\n",
    "                matches = re.findall(r'(\\d+)%_(\\w+)', grape)\n",
    "\n",
    "                if len(matches) == 1:\n",
    "                    percentage, grape  = matches[0]\n",
    "                    if int(percentage) >= threshold: tmp[grape2idx[grape]] = 1\n",
    "\n",
    "                else: tmp[grape2idx[grape]] = 1\n",
    "        grape_onehot.append(tmp)\n",
    "    wine_info['grape_label'] = grape_onehot\n",
    "    return wine_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lowcount_feat(df, col, threshold):\n",
    "    feats = {}\n",
    "    idx = 1\n",
    "    for feature, count in zip(df[col].value_counts().index,  df[col].value_counts()):\n",
    "        if count >= threshold:\n",
    "            feats[feature] = idx\n",
    "            idx += 1\n",
    "        else:\n",
    "            feats[feature] = 0\n",
    "    return feats\n",
    "\n",
    "def string2label(df, column, feature2idx):\n",
    "    labels = []\n",
    "    df[column] = df[column].fillna(\"None\")\n",
    "    for feature in tqdm(df[column]):\n",
    "        tmp = [0 for _ in range(max(feature2idx.values())+1)]\n",
    "\n",
    "        if feature in feature2idx:\n",
    "            tmp[feature2idx[feature]] = 1\n",
    "        else: tmp[-1] = 0\n",
    "\n",
    "        labels.append(tmp)\n",
    "        \n",
    "    df[f\"{column}_label\"] = labels\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/opt/ml/wine/code/data/feature_map/item2idx.json','r') as f:\n",
    "    item2idx = json.load(f)\n",
    "wine_info['wine_id'] = wine_info['url'].map(item2idx)\n",
    "wine_info = wine_info[wine_info['wine_id'].isna()==False]\n",
    "wine_info['wine_id'] = wine_info['wine_id'].astype('int').astype('category')\n",
    "wine_info = wine_info.loc[:,['wine_id','country','grapes','winetype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13071/13071 [00:00<00:00, 309270.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10543/10543 [00:00<00:00, 407374.92it/s]\n",
      "100%|██████████| 10543/10543 [00:00<00:00, 325925.15it/s]\n"
     ]
    }
   ],
   "source": [
    "wine_info, grape2idx, country2idx, winetype2idx = gen_labeled_data(wine_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine_id</th>\n",
       "      <th>country</th>\n",
       "      <th>grapes</th>\n",
       "      <th>winetype</th>\n",
       "      <th>grape_label</th>\n",
       "      <th>winetype_label</th>\n",
       "      <th>country_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>France</td>\n",
       "      <td>[chenin_blanc]</td>\n",
       "      <td>White wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>France</td>\n",
       "      <td>[gamay]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>South_Africa</td>\n",
       "      <td>[chenin_blanc]</td>\n",
       "      <td>White wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>France</td>\n",
       "      <td>[pinot_noir]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Italy</td>\n",
       "      <td>[sangiovese, cabernet_sauvignon]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10538</th>\n",
       "      <td>74884</td>\n",
       "      <td>Spain</td>\n",
       "      <td>[shiraz/syrah, merlot, cabernet_sauvignon, gre...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>74893</td>\n",
       "      <td>France</td>\n",
       "      <td>[pinot_noir]</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>74901</td>\n",
       "      <td>United_States</td>\n",
       "      <td>[chardonnay]</td>\n",
       "      <td>White wine</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>74910</td>\n",
       "      <td>United_States</td>\n",
       "      <td>[sauvignon_blanc]</td>\n",
       "      <td>White wine</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>74913</td>\n",
       "      <td>France</td>\n",
       "      <td>[cabernet_sauvignon, cabernet_franc, malbec, m...</td>\n",
       "      <td>Red wine</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10543 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wine_id        country  \\\n",
       "0           9         France   \n",
       "1          19         France   \n",
       "2          24   South_Africa   \n",
       "3          35         France   \n",
       "4          37          Italy   \n",
       "...       ...            ...   \n",
       "10538   74884          Spain   \n",
       "10539   74893         France   \n",
       "10540   74901  United_States   \n",
       "10541   74910  United_States   \n",
       "10542   74913         France   \n",
       "\n",
       "                                                  grapes    winetype  \\\n",
       "0                                         [chenin_blanc]  White wine   \n",
       "1                                                [gamay]    Red wine   \n",
       "2                                         [chenin_blanc]  White wine   \n",
       "3                                           [pinot_noir]    Red wine   \n",
       "4                       [sangiovese, cabernet_sauvignon]    Red wine   \n",
       "...                                                  ...         ...   \n",
       "10538  [shiraz/syrah, merlot, cabernet_sauvignon, gre...    Red wine   \n",
       "10539                                       [pinot_noir]    Red wine   \n",
       "10540                                       [chardonnay]  White wine   \n",
       "10541                                  [sauvignon_blanc]  White wine   \n",
       "10542  [cabernet_sauvignon, cabernet_franc, malbec, m...    Red wine   \n",
       "\n",
       "                                             grape_label  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "10538  [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10539  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10540  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10541  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "10542  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "\n",
       "                 winetype_label                         country_label  \n",
       "0      [0, 0, 1, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [0, 0, 1, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "3      [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4      [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                         ...                                   ...  \n",
       "10538  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10539  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10540  [0, 0, 1, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10541  [0, 0, 1, 0, 0, 0, 0, 0]  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10542  [0, 1, 0, 0, 0, 0, 0, 0]  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[10543 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labeled_data(\n",
    "        wine_info : pd.DataFrame, \n",
    "        grape_threshold : int = 89, \n",
    "        grape_percentage_threshold : int = 20,\n",
    "        country_threshold : int = 150,\n",
    "        winetype_threshold : int = 0\n",
    "        ):\n",
    "    wine_info.drop_duplicates(inplace = True)\n",
    "    wine_info = wine_info.loc[:,['wine_id','country','grapes','winetype']]\n",
    "    wine_info['country'].fillna('other', inplace = True)\n",
    "    wine_info['winetype'].fillna('other', inplace = True)\n",
    "    wine_info['grapes'] = wine_info['grapes'].apply(str2list)\n",
    "\n",
    "    unique_grape = get_all_grapes(wine_info)\n",
    "    filtered_grape = {k: v for k, v in unique_grape.items() if v >=grape_threshold}\n",
    "    grape2idx =  {k: v for v, k in enumerate(filtered_grape.keys())}\n",
    "\n",
    "    wine_info = grape_encoding(wine_info, grape2idx, grape_percentage_threshold)\n",
    "    sum_zero_filter = lambda x: sum(x) != 0\n",
    "\n",
    "    # Apply the filter and drop rows where the sum of the list is 0\n",
    "    wine_info = wine_info[wine_info['grape_label'].apply(sum_zero_filter)]\n",
    "\n",
    "    country2idx =  cut_lowcount_feat(wine_info, 'country', country_threshold)\n",
    "    winetype2idx = cut_lowcount_feat(wine_info, 'winetype', winetype_threshold)\n",
    "\n",
    "    wine_info = string2label(wine_info, 'winetype', winetype2idx)\n",
    "    wine_info = string2label(wine_info, 'country', country2idx)\n",
    "    wine_info.reset_index(inplace = True, drop = True)\n",
    "    return wine_info, grape2idx, country2idx, winetype2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_info.to_csv('/opt/ml/wine/data/wine_label_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price_in_review(text, price_vocab):\n",
    "    price_vocab = set(price_vocab)\n",
    "    text = text.lower()\n",
    "    if any(word in text for word in price_vocab): return [1]\n",
    "    else: return [0]\n",
    "\n",
    "def marking_price_data(df, price_vocab):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    df['text'] = df['text'].fillna('')\n",
    "    data = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        tmp = {}\n",
    "        tmp['text'] = df.loc[i,'text']\n",
    "        tmp['label'] = check_price_in_review(df.loc[i,'text'], price_vocab)\n",
    "        data.append(tmp)\n",
    "        \n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7649958/7649958 [04:24<00:00, 28931.42it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/wine/data/price_vocab.json','r') as f: price_vocab = json.load(f)\n",
    "price_data = marking_price_data(review_df, price_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-9308ff83ffc9>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')\n",
      "<ipython-input-67-9308ff83ffc9>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_df.drop(['index','level_0','user_url','wine_url'], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "review_df\n",
    "review_df['wine_id'] = review_df['wine_url'].map(item2idx)\n",
    "review_df = review_df[review_df['wine_id'].isna()==False]\n",
    "review_df['wine_id'] = review_df['wine_id'].astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_text(x):\n",
    "    return len(x.split())\n",
    "\n",
    "review_df = review_df.sort_values('wine_id')\n",
    "review_df['length'] = review_df['text'].apply(get_len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = review_df.sort_values(['wine_id', 'length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_short_review(df, threshold):\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    data = []\n",
    "\n",
    "    prv_text = ''\n",
    "    prv_id = -1\n",
    "    for i in tqdm(range(len(df))):\n",
    "        tmp = {}\n",
    "        \n",
    "        wine_id = df.loc[i, 'wine_id']\n",
    "        length = df.loc[i, 'length']\n",
    "        text = df.loc[i, 'text']\n",
    "        \n",
    "        if length <= threshold: \n",
    "            if length + len(prv_text.split()) > threshold:\n",
    "                if wine_id == prv_id:\n",
    "                    text += prv_text\n",
    "                    length += len(prv_text.split())\n",
    "                    prv_text = ''\n",
    "\n",
    "                tmp['wine_id'] = wine_id\n",
    "                tmp['text'] = text\n",
    "                tmp['length'] = length \n",
    "                data.append(tmp)\n",
    "\n",
    "            else:\n",
    "                prv_text += text\n",
    "                prv_id = wine_id\n",
    "        else:\n",
    "            tmp['wine_id'] = wine_id\n",
    "            tmp['text'] = text\n",
    "            tmp['length'] = length\n",
    "            data.append(tmp)\n",
    "    \n",
    "    result = pd.DataFrame(data)\n",
    "    print(f\"Before : {len(df)}\")\n",
    "    print(f\"After : {len(result)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7432485/7432485 [04:32<00:00, 27281.42it/s]\n"
     ]
    }
   ],
   "source": [
    "review_df = merge_short_review(review_df, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
